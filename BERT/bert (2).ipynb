{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPW3MFvGQw6J7Zp/M4YE4AY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"b8731c29a0c34a3883377ca4f98139d6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8f5cfe0005524381aec09744a67cd144","IPY_MODEL_44b179dc38af44fd9e5c907c3ed92fee","IPY_MODEL_3065d1719b974057b930f4f91e4c9a84"],"layout":"IPY_MODEL_20a2032687774c80a5909ee2a2017d76"}},"8f5cfe0005524381aec09744a67cd144":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3a176a0f1f6741bab5a0474cb81aa5b7","placeholder":"​","style":"IPY_MODEL_44f6bd1556cb439ba8c4d9ff2cb55cb6","value":"Downloading model.safetensors: 100%"}},"44b179dc38af44fd9e5c907c3ed92fee":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b057741ab2554147873b26c8ddd86f09","max":440449768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_be23d43888cc4f5c978a46c2cc547879","value":440449768}},"3065d1719b974057b930f4f91e4c9a84":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f9bd716f365946cb8a24ee7bbc3535e3","placeholder":"​","style":"IPY_MODEL_0c6018f98d484e678caa74a193748ca0","value":" 440M/440M [00:08&lt;00:00, 44.8MB/s]"}},"20a2032687774c80a5909ee2a2017d76":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a176a0f1f6741bab5a0474cb81aa5b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"44f6bd1556cb439ba8c4d9ff2cb55cb6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b057741ab2554147873b26c8ddd86f09":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be23d43888cc4f5c978a46c2cc547879":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f9bd716f365946cb8a24ee7bbc3535e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c6018f98d484e678caa74a193748ca0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d22v8Sf7i6o6","executionInfo":{"status":"ok","timestamp":1686591508433,"user_tz":420,"elapsed":6919,"user":{"displayName":"Shiyao Guo","userId":"16390484205648521981"}},"outputId":"01e1566e-bd6c-4bd7-93d2-35b174002233"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.30.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uxiOV50hjcIa","executionInfo":{"status":"ok","timestamp":1686591511346,"user_tz":420,"elapsed":1148,"user":{"displayName":"Shiyao Guo","userId":"16390484205648521981"}},"outputId":"ed646844-940f-4ec3-b9f9-b05de6c7a63f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ULjVZE7oiYgc"},"outputs":[],"source":["\n","import pandas as pd\n","import json\n","import torch\n","import ast\n","from torch.utils.data import DataLoader\n","from transformers import BertTokenizer, BertForTokenClassification, AdamW\n","from torch.nn.utils.rnn import pad_sequence\n","import torch.nn.utils.rnn as rnn_utils\n","from sklearn.metrics import classification_report, f1_score, precision_score, recall_score\n","\n"]},{"cell_type":"code","source":["df=pd.read_csv('train.csv')\n","\n","labels=[]\n","tokens=[]\n","print(df['span_start_index'][0][0])\n","for ind in df.index:\n","\tlabel=[]\n","\n","\tspan_start=json.loads(df['span_start_index'][ind])\n","\tspan_end=json.loads(df['span_end_index'][ind])\n","\ttoken=ast.literal_eval((df['tokens'][ind]))\n","\ttokens.append(token)\n","\tfor i in range(len(token)):\n","\t\tflag=False\n","\t\tfor j in range(len(span_start)):\n","\t\t\tif span_start[j]<i<=span_end[j]:\n","\t\t\t\tlabel.append('I')\n","\t\t\t\tflag=True\n","\t\t\t\tcontinue\n","\t\tif flag==True:\n","\t\t\tcontinue\n","\t\tif i in span_start:\n","\t\t\tlabel.append('B')\n","\t\telse:\n","\t\t\tlabel.append('O')\n","\tlabels.append(label)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZfojtoQYi5BV","executionInfo":{"status":"ok","timestamp":1686591625376,"user_tz":420,"elapsed":1463,"user":{"displayName":"Shiyao Guo","userId":"16390484205648521981"}},"outputId":"b82fe4a4-e275-4e03-a2cc-22da5fe2be9e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[\n"]}]},{"cell_type":"code","source":["tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","\n","\n","label_dict = {'O':0,'B':1,'I':2}\n","\n","\n","int_labels = []\n","\n","for i in labels:\n","\tfor j in range(len(i)):\n","\t\ti[j]=label_dict[i[j]]\n","labelss=labels\n","\n","\n","\n","\n","\n","#print(type(tokens))\n","def convert_to_input(texts, labels):\n","    input_ids = []\n","    attention_masks = []\n","    token_type_ids = []\n","    new_labels = []\n","    max_seq_len = max([len(seq) for seq in texts])\n","\n","    for text, label in zip(texts, labels):\n","        tokens = []\n","        token_labels = []\n","        for word, lbl in zip(text, label):\n","            word_tokens = tokenizer.tokenize(word)\n","            tokens.extend(word_tokens)\n","            token_labels.extend([lbl] * len(word_tokens))\n","\n","        tokens = ['[CLS]'] + tokens + ['[SEP]']\n","\n","\n","        token_labels = [0] + token_labels + [0]\n","        input_id = tokenizer.convert_tokens_to_ids(tokens)\n","\n","        attention_mask=[]\n","        for i in range(len(input_id)):\n","            if token_labels[i]==0:\n","                attention_mask.append(0)\n","            else:\n","                attention_mask.append(1)\n","        #attention_mask = [1] * len(input_id)\n","        token_type_id = [0] * len(input_id)\n","\n","\n","\n","\n","        input_ids.append(input_id)\n","        attention_masks.append(attention_mask)\n","        token_type_ids.append(token_type_id)\n","\n","        new_labels.append(token_labels)\n","\n","\n","    input_ids = pad_sequence([torch.tensor(ids, dtype=torch.long) for ids in input_ids], batch_first=True, padding_value=0)\n","    attention_masks = pad_sequence([torch.tensor(mask, dtype=torch.long) for mask in attention_masks], batch_first=True, padding_value=0)\n","    token_type_ids = pad_sequence([torch.tensor(ids, dtype=torch.long) for ids in token_type_ids], batch_first=True, padding_value=0)\n","    labels = pad_sequence([torch.tensor(lbls, dtype=torch.long) for lbls in new_labels], batch_first=True, padding_value=0)\n","\n","\n","\n","\n","\n","\n","    return input_ids, attention_masks, token_type_ids, labels\n","\n","input_ids, attention_masks, token_type_ids, labels = convert_to_input(tokens, labelss)\n","print(len(input_ids))\n","print(len(attention_masks))\n","print(len(token_type_ids))\n","print(len(labels))\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":252},"id":"kEnLUFF8jwBA","executionInfo":{"status":"ok","timestamp":1686591642127,"user_tz":420,"elapsed":10301,"user":{"displayName":"Shiyao Guo","userId":"16390484205648521981"}},"outputId":"92af344b-9f41-44f0-a4b7-441acabf0d5a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[CLS]\n","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0]\n","6044\n","6044\n","6044\n","6044\n","['[CLS]', '\"', 'who', 'may', '(', 'or', 'may', 'not', ')', 'have', 'it', '\"', '-', 'sc', '##hr', '##od', '##inger', \"'\", 's', 'virus', '.', 'we', 'can', 'not', 'get', 'tested', ',', 'so', 'we', 'have', 'to', 'act', 'like', 'we', 'have', 'the', 'virus', 'so', 'we', 'do', 'not', 'spread', 'it', '.', 'we', 'also', 'have', 'to', 'act', 'like', 'we', 'have', 'never', 'had', 'the', 'virus', ',', 'because', 'if', 'we', 'have', 'not', 'had', 'the', 'virus', ',', 'we', 'are', 'not', 'immune', '.', '#', 'co', '##vid', '##19', '[SEP]']\n"]},{"output_type":"execute_result","data":{"text/plain":["'input_ids = pad_sequence(input_ids, batch_first=True, padding_value=0)\\nattention_masks = pad_sequence(attention_masks, batch_first=True, padding_value=0)\\ntoken_type_ids = pad_sequence(token_type_ids, batch_first=True, padding_value=0)\\n\\ninput_ids = torch.tensor(input_ids)\\nattention_masks = torch.tensor(attention_masks)\\ntoken_type_ids = torch.tensor(token_type_ids)\\nlabels = []\\nfor lbl in new_labels:\\n    labels.extend(lbl)\\nlabels = torch.tensor(labels)'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["model = BertForTokenClassification.from_pretrained('bert-base-uncased', num_labels=3)  # Adjust num_labels according to your dataset\n","optimizer = AdamW(model.parameters(), lr=1e-4)\n","batch_size = 32\n","dataset = torch.utils.data.TensorDataset(input_ids, attention_masks,labels)\n","dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n","\n","epochs = 3\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","for epoch in range(epochs):\n","    print(f\"Epoch {epoch+1}/{epochs}\")\n","    print(\"-\" * 10)\n","\n","    model.train()\n","    total_loss = 0\n","    for batch in dataloader:\n","        batch = tuple(t.to(device) for t in batch)\n","        input_ids, attention_masks, labels = batch\n","\n","\n","\n","\n","        if input_ids.size(0) != labels.size(0):\n","            continue\n","        # Forward pass\n","        outputs = model(input_ids, attention_mask=attention_masks, labels=labels)\n","        loss = outputs.loss\n","        total_loss += loss.item()\n","\n","        # Backward pass and optimization\n","        loss.backward()\n","        optimizer.step()\n","        optimizer.zero_grad()\n","\n","    average_loss = total_loss / len(dataloader)\n","    print(f\"Average Loss: {average_loss:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":355,"referenced_widgets":["b8731c29a0c34a3883377ca4f98139d6","8f5cfe0005524381aec09744a67cd144","44b179dc38af44fd9e5c907c3ed92fee","3065d1719b974057b930f4f91e4c9a84","20a2032687774c80a5909ee2a2017d76","3a176a0f1f6741bab5a0474cb81aa5b7","44f6bd1556cb439ba8c4d9ff2cb55cb6","b057741ab2554147873b26c8ddd86f09","be23d43888cc4f5c978a46c2cc547879","f9bd716f365946cb8a24ee7bbc3535e3","0c6018f98d484e678caa74a193748ca0"]},"id":"bq0sXscuj7Ru","executionInfo":{"status":"ok","timestamp":1686589562572,"user_tz":420,"elapsed":470121,"user":{"displayName":"Shiyao Guo","userId":"16390484205648521981"}},"outputId":"74c4f11b-b25a-4cd2-bccc-821f391ad44f"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8731c29a0c34a3883377ca4f98139d6"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","----------\n","Average Loss: 0.0773\n","Epoch 2/3\n","----------\n","Average Loss: 0.0092\n","Epoch 3/3\n","----------\n","Average Loss: 0.0043\n"]}]},{"cell_type":"code","source":["model.eval()\n","predicted_labels = []\n","true_labels = []\n","\n","with torch.no_grad():\n","    for batch in dataloader:\n","        batch = tuple(t.to(device) for t in batch)\n","        input_ids, attention_masks, labels = batch\n","\n","        # Forward pass\n","        outputs = model(input_ids, attention_mask=attention_masks)\n","        logits = outputs.logits\n","\n","        # Get predicted labels\n","        predicted_labels.extend(torch.argmax(logits, dim=2).tolist())\n","        true_labels.extend(labels.tolist())\n","\n","# Flatten the predicted and true labels\n","predicted_labels = [label for sublist in predicted_labels for label in sublist]\n","true_labels = [label for sublist in true_labels for label in sublist]\n","\n","# Compute metrics\n","report = classification_report(true_labels, predicted_labels)\n","f1 = f1_score(true_labels, predicted_labels, average='micro')\n","precision = precision_score(true_labels, predicted_labels, average='micro')\n","recall = recall_score(true_labels, predicted_labels, average='micro')\n","\n","# Print metrics\n","print(report)\n","print(f\"F1 Score: {f1:.4f}\")\n","print(f\"Precision: {precision:.4f}\")\n","print(f\"Recall: {recall:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sjVxkJGdm3_I","executionInfo":{"status":"ok","timestamp":1686589713748,"user_tz":420,"elapsed":53999,"user":{"displayName":"Shiyao Guo","userId":"16390484205648521981"}},"outputId":"26614be2-4181-4271-d7c0-e6c90e0fc593"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00    875330\n","           1       0.99      0.98      0.99     14518\n","           2       1.00      1.00      1.00     95324\n","\n","    accuracy                           1.00    985172\n","   macro avg       1.00      0.99      1.00    985172\n","weighted avg       1.00      1.00      1.00    985172\n","\n","F1 Score: 0.9996\n","Precision: 0.9996\n","Recall: 0.9996\n"]}]},{"cell_type":"code","source":["df=pd.read_csv('dev.csv')\n","#print(type(train))\n","labels=[]\n","tokens=[]\n","print(df['span_start_index'][0][0])\n","for ind in df.index:\n","\tlabel=[]\n","\n","\tspan_start=json.loads(df['span_start_index'][ind])\n","\tspan_end=json.loads(df['span_end_index'][ind])\n","\ttoken=ast.literal_eval((df['tokens'][ind]))\n","\ttokens.append(token)\n","\tfor i in range(len(token)):\n","\t\tflag=False\n","\t\tfor j in range(len(span_start)):\n","\t\t\tif span_start[j]<i<=span_end[j]:\n","\t\t\t\tlabel.append('I')\n","\t\t\t\tflag=True\n","\t\t\t\tcontinue\n","\t\tif flag==True:\n","\t\t\tcontinue\n","\t\tif i in span_start:\n","\t\t\tlabel.append('B')\n","\t\telse:\n","\t\t\tlabel.append('O')\n","\tlabels.append(label)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-gr6-s0zr5ek","executionInfo":{"status":"ok","timestamp":1686589726366,"user_tz":420,"elapsed":400,"user":{"displayName":"Shiyao Guo","userId":"16390484205648521981"}},"outputId":"103be62f-2ff8-4ede-ed74-1fcf778ed46a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[\n"]}]},{"cell_type":"code","source":["tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","\n","# dictionary that maps integer to its string value\n","label_dict = {'O':0,'B':1,'I':2}\n","\n","# list to store integer labels\n","int_labels = []\n","\n","for i in labels:\n","\tfor j in range(len(i)):\n","\t\ti[j]=label_dict[i[j]]\n","labelss=labels\n","#print(labels[0])\n","input_ids, attention_masks, token_type_ids, labels = convert_to_input(tokens, labelss)\n","batch_size = 32\n","dataset = torch.utils.data.TensorDataset(input_ids, attention_masks,labels)\n","dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n","model.eval()\n","predicted_labels = []\n","true_labels = []\n","\n","with torch.no_grad():\n","    for batch in dataloader:\n","        batch = tuple(t.to(device) for t in batch)\n","        input_ids, attention_masks, labels = batch\n","\n","        # Forward pass\n","        outputs = model(input_ids, attention_mask=attention_masks)\n","        logits = outputs.logits\n","\n","        # Get predicted labels\n","        predicted_labels.extend(torch.argmax(logits, dim=2).tolist())\n","        true_labels.extend(labels.tolist())\n","\n","# Flatten the predicted and true labels\n","predicted_labels = [label for sublist in predicted_labels for label in sublist]\n","true_labels = [label for sublist in true_labels for label in sublist]\n","\n","# Compute metrics\n","report = classification_report(true_labels, predicted_labels)\n","f1 = f1_score(true_labels, predicted_labels, average='micro')\n","precision = precision_score(true_labels, predicted_labels, average='micro')\n","recall = recall_score(true_labels, predicted_labels, average='micro')\n","\n","# Print metrics\n","print(report)\n","print(f\"F1 Score: {f1:.4f}\")\n","print(f\"Precision: {precision:.4f}\")\n","print(f\"Recall: {recall:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2rEXfkOwsNTn","executionInfo":{"status":"ok","timestamp":1686589738538,"user_tz":420,"elapsed":9745,"user":{"displayName":"Shiyao Guo","userId":"16390484205648521981"}},"outputId":"928f27ff-b969-4d93-fe15-88c73ce8196e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     63442\n","           1       0.97      0.94      0.96      1798\n","           2       0.99      1.00      0.99     11872\n","\n","    accuracy                           1.00     77112\n","   macro avg       0.99      0.98      0.98     77112\n","weighted avg       1.00      1.00      1.00     77112\n","\n","F1 Score: 0.9979\n","Precision: 0.9979\n","Recall: 0.9979\n"]}]}]}